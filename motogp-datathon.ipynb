{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607caaec",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-14T06:17:15.562977Z",
     "iopub.status.busy": "2025-06-14T06:17:15.562715Z",
     "iopub.status.idle": "2025-06-14T06:17:17.071473Z",
     "shell.execute_reply": "2025-06-14T06:17:17.070254Z"
    },
    "papermill": {
     "duration": 1.516297,
     "end_time": "2025-06-14T06:17:17.072904",
     "exception": false,
     "start_time": "2025-06-14T06:17:15.556607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/burnout-datathon-ieeecsmuj/sample_submission.csv\n",
      "/kaggle/input/burnout-datathon-ieeecsmuj/val.csv\n",
      "/kaggle/input/burnout-datathon-ieeecsmuj/train.csv\n",
      "/kaggle/input/burnout-datathon-ieeecsmuj/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571b3545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:17:17.082453Z",
     "iopub.status.busy": "2025-06-14T06:17:17.082054Z",
     "iopub.status.idle": "2025-06-14T06:17:24.638346Z",
     "shell.execute_reply": "2025-06-14T06:17:24.637444Z"
    },
    "papermill": {
     "duration": 7.562527,
     "end_time": "2025-06-14T06:17:24.639797",
     "exception": false,
     "start_time": "2025-06-14T06:17:17.077270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Advanced ML\n",
    "from sklearn.ensemble import StackingRegressor, VotingRegressor\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import gc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d0f92",
   "metadata": {
    "papermill": {
     "duration": 0.003671,
     "end_time": "2025-06-14T06:17:24.647705",
     "exception": false,
     "start_time": "2025-06-14T06:17:24.644034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. DATA LOADING AND EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d30dce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:17:24.656623Z",
     "iopub.status.busy": "2025-06-14T06:17:24.656014Z",
     "iopub.status.idle": "2025-06-14T06:17:38.449992Z",
     "shell.execute_reply": "2025-06-14T06:17:38.448988Z"
    },
    "papermill": {
     "duration": 13.799612,
     "end_time": "2025-06-14T06:17:38.451057",
     "exception": false,
     "start_time": "2025-06-14T06:17:24.651445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ MOTOGP DATATHON - WINNING STRATEGY EXECUTION\n",
      "============================================================\n",
      "üìä Loading Data...\n",
      "Training data shape: (1914056, 45)\n",
      "Test data shape: (546874, 44)\n",
      "Columns: ['Unique ID', 'Rider_ID', 'category_x', 'Circuit_Length_km', 'Laps', 'Grid_Position', 'Avg_Speed_kmh', 'Track_Condition', 'Humidity_%', 'Tire_Compound_Front', 'Tire_Compound_Rear', 'Penalty', 'Championship_Points', 'Championship_Position', 'Session', 'year_x', 'sequence', 'rider', 'team', 'bike', 'position', 'points', 'shortname', 'circuit_name', 'rider_name', 'team_name', 'bike_name', 'Lap_Time_Seconds', 'Corners_per_Lap', 'Tire_Degradation_Factor_per_Lap', 'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius', 'Track_Temperature_Celsius', 'weather', 'track', 'air', 'ground', 'starts', 'finishes', 'with_points', 'podiums', 'wins', 'min_year', 'max_year', 'years_active']\n",
      "\n",
      "üéØ Target Analysis:\n",
      "Mean lap time: 90.00s\n",
      "Std lap time: 11.53s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.feature_selection import SelectKBest, f_regression  \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "def main_pipeline():\n",
    "    \n",
    "    print(\"üèÅ MOTOGP DATATHON - WINNING STRATEGY EXECUTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"üìä Loading Data...\")\n",
    "    train = pd.read_csv('/kaggle/input/burnout-datathon-ieeecsmuj/train.csv')\n",
    "    test = pd.read_csv('/kaggle/input/burnout-datathon-ieeecsmuj/test.csv')\n",
    "    \n",
    "    print(f\"Training data shape: {train.shape}\")\n",
    "    print(f\"Test data shape: {test.shape}\")\n",
    "    print(f\"Columns: {list(train.columns)}\")\n",
    "\n",
    "    print(f\"\\nüéØ Target Analysis:\")\n",
    "    print(f\"Mean lap time: {train['Lap_Time_Seconds'].mean():.2f}s\")\n",
    "    print(f\"Std lap time: {train['Lap_Time_Seconds'].std():.2f}s\")\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "train, test = main_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b72ac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:17:38.459870Z",
     "iopub.status.busy": "2025-06-14T06:17:38.459582Z",
     "iopub.status.idle": "2025-06-14T06:17:47.121681Z",
     "shell.execute_reply": "2025-06-14T06:17:47.121007Z"
    },
    "papermill": {
     "duration": 8.668035,
     "end_time": "2025-06-14T06:17:47.123125",
     "exception": false,
     "start_time": "2025-06-14T06:17:38.455090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Loading Data...\n",
      "Training data shape: (1914056, 45)\n",
      "Test data shape: (546874, 44)\n",
      "Target variable: Lap_Time_Seconds\n",
      "\n",
      "Target Statistics:\n",
      "Mean: 90.00 seconds\n",
      "Std: 11.53 seconds\n",
      "Min: 70.00 seconds\n",
      "Max: 110.00 seconds\n",
      "\n",
      "Missing values in train: 321292\n",
      "Missing values in test: 91555\n"
     ]
    }
   ],
   "source": [
    "def load_and_explore_data():\n",
    "    print(\"\\nüìä Loading Data...\")\n",
    "    \n",
    "    train = pd.read_csv('/kaggle/input/burnout-datathon-ieeecsmuj/train.csv')\n",
    "    test = pd.read_csv('/kaggle/input/burnout-datathon-ieeecsmuj/test.csv')\n",
    "    \n",
    "    print(f\"Training data shape: {train.shape}\")\n",
    "    print(f\"Test data shape: {test.shape}\")\n",
    "    print(f\"Target variable: Lap_Time_Seconds\")\n",
    "    \n",
    "    print(f\"\\nTarget Statistics:\")\n",
    "    print(f\"Mean: {train['Lap_Time_Seconds'].mean():.2f} seconds\")\n",
    "    print(f\"Std: {train['Lap_Time_Seconds'].std():.2f} seconds\")\n",
    "    print(f\"Min: {train['Lap_Time_Seconds'].min():.2f} seconds\")\n",
    "    print(f\"Max: {train['Lap_Time_Seconds'].max():.2f} seconds\")\n",
    "    \n",
    "    print(f\"\\nMissing values in train: {train.isnull().sum().sum()}\")\n",
    "    print(f\"Missing values in test: {test.isnull().sum().sum()}\")\n",
    "    \n",
    "    return train, test\n",
    "train, test = load_and_explore_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae25f1",
   "metadata": {
    "papermill": {
     "duration": 0.003794,
     "end_time": "2025-06-14T06:17:47.131550",
     "exception": false,
     "start_time": "2025-06-14T06:17:47.127756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PHASE 2: FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9779cc51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:17:47.140776Z",
     "iopub.status.busy": "2025-06-14T06:17:47.140512Z",
     "iopub.status.idle": "2025-06-14T06:17:47.971761Z",
     "shell.execute_reply": "2025-06-14T06:17:47.971046Z"
    },
    "papermill": {
     "duration": 0.837224,
     "end_time": "2025-06-14T06:17:47.972810",
     "exception": false,
     "start_time": "2025-06-14T06:17:47.135586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in train dataset:\n",
      "['Unique ID', 'Rider_ID', 'category_x', 'Circuit_Length_km', 'Laps', 'Grid_Position', 'Avg_Speed_kmh', 'Track_Condition', 'Humidity_%', 'Tire_Compound_Front', 'Tire_Compound_Rear', 'Penalty', 'Championship_Points', 'Championship_Position', 'Session', 'year_x', 'sequence', 'rider', 'team', 'bike', 'position', 'points', 'shortname', 'circuit_name', 'rider_name', 'team_name', 'bike_name', 'Lap_Time_Seconds', 'Corners_per_Lap', 'Tire_Degradation_Factor_per_Lap', 'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius', 'Track_Temperature_Celsius', 'weather', 'track', 'air', 'ground', 'starts', 'finishes', 'with_points', 'podiums', 'wins', 'min_year', 'max_year', 'years_active']\n",
      "\n",
      "DataFrame shape: (1914056, 45)\n",
      "\n",
      "First few rows:\n",
      "   Unique ID  Rider_ID category_x  Circuit_Length_km  Laps  Grid_Position  \\\n",
      "0    1894944      2659      Moto2              4.874    22             17   \n",
      "1      23438      5205      Moto2              3.875    24              7   \n",
      "2     939678      7392      Moto3              5.647    25              5   \n",
      "3    1196312      7894      Moto3              4.810    19              3   \n",
      "4    1033899      6163     MotoGP              5.809    25             21   \n",
      "\n",
      "   Avg_Speed_kmh Track_Condition  Humidity_% Tire_Compound_Front  ... air  \\\n",
      "0         264.66             Wet          61                Hard  ...  23   \n",
      "1         177.56             Wet          77                Soft  ...  12   \n",
      "2         317.74             Dry          87                Soft  ...  22   \n",
      "3         321.82             Wet          43                Soft  ...  23   \n",
      "4         239.92             Wet          47                Hard  ...  22   \n",
      "\n",
      "  ground  starts  finishes with_points  podiums  wins  min_year  max_year  \\\n",
      "0     35      53        45          41        4     0      2018      2021   \n",
      "1     12      27        27          22        2     1      1975      1983   \n",
      "2     23      45        43          10        0     0      1982      1989   \n",
      "3     35     192       172         155       16     9      1994      2009   \n",
      "4     31     175       146         132       29    17      2011      2021   \n",
      "\n",
      "   years_active  \n",
      "0             4  \n",
      "1             8  \n",
      "2             8  \n",
      "3            16  \n",
      "4            11  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "Columns containing 'start' (case insensitive):\n",
      "['starts']\n",
      "\n",
      "Columns containing 'race' (case insensitive):\n",
      "[]\n",
      "\n",
      "Columns containing 'finish' (case insensitive):\n",
      "['finishes']\n",
      "\n",
      "üõ†Ô∏è PHASE 2: FEATURE ENGINEERING (CORRECTED)\n",
      "==================================================\n",
      "Working with 45 columns\n",
      "Working with 44 columns\n",
      "\n",
      "‚úÖ Features created! Train shape: (1914056, 64)\n",
      "\n",
      "üéØ New feature count: 19 features added\n",
      "Total features now: 64\n",
      "\n",
      "üÜï New features created: 19\n",
      "   - championship_momentum\n",
      "   - corners_per_km\n",
      "   - distance_per_corner\n",
      "   - experience_points_ratio\n",
      "   - finish_rate\n",
      "   - grid_advantage\n",
      "   - humidity_temp_interaction\n",
      "   - podium_rate\n",
      "   - points_per_start\n",
      "   - position_pressure\n",
      "   - speed_per_corner\n",
      "   - speed_temp_interaction\n",
      "   - starts_per_year\n",
      "   - temp_diff\n",
      "   - theoretical_lap_time\n",
      "   - tire_degradation_total\n",
      "   - tire_strategy\n",
      "   - total_race_distance\n",
      "   - win_rate\n"
     ]
    }
   ],
   "source": [
    "print(\"Available columns in train dataset:\")\n",
    "print(train.columns.tolist())\n",
    "print(f\"\\nDataFrame shape: {train.shape}\")\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(train.head())\n",
    "\n",
    "print(\"\\nColumns containing 'start' (case insensitive):\")\n",
    "start_cols = [col for col in train.columns if 'start' in col.lower()]\n",
    "print(start_cols)\n",
    "\n",
    "print(\"\\nColumns containing 'race' (case insensitive):\")\n",
    "race_cols = [col for col in train.columns if 'race' in col.lower()]  \n",
    "print(race_cols)\n",
    "\n",
    "print(\"\\nColumns containing 'finish' (case insensitive):\")\n",
    "finish_cols = [col for col in train.columns if 'finish' in col.lower()]\n",
    "print(finish_cols)\n",
    "def phase2_feature_engineering_corrected(train_df, test_df):\n",
    "    \n",
    "    print(\"\\nüõ†Ô∏è PHASE 2: FEATURE ENGINEERING (CORRECTED)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    def create_features(df):\n",
    "        df = df.copy()\n",
    "        available_cols = df.columns.tolist()\n",
    "        print(f\"Working with {len(available_cols)} columns\")\n",
    "        \n",
    "        if 'Championship_Points' in available_cols and 'starts' in available_cols:\n",
    "            df['points_per_start'] = df['Championship_Points'] / (df['starts'] + 1)\n",
    "        \n",
    "        if 'podiums' in available_cols and 'finishes' in available_cols:\n",
    "            df['podium_rate'] = df['podiums'] / (df['finishes'] + 1)\n",
    "            \n",
    "        if 'wins' in available_cols and 'finishes' in available_cols:\n",
    "            df['win_rate'] = df['wins'] / (df['finishes'] + 1)\n",
    "            \n",
    "        if 'finishes' in available_cols and 'starts' in available_cols:\n",
    "            df['finish_rate'] = df['finishes'] / (df['starts'] + 1)\n",
    "        \n",
    "        if all(col in available_cols for col in ['Corners_per_Lap', 'Circuit_Length_km']):\n",
    "            df['corners_per_km'] = df['Corners_per_Lap'] / (df['Circuit_Length_km'] + 0.001)\n",
    "            df['distance_per_corner'] = df['Circuit_Length_km'] / (df['Corners_per_Lap'] + 1)\n",
    "            \n",
    "        if all(col in available_cols for col in ['Circuit_Length_km', 'Laps']):\n",
    "            df['total_race_distance'] = df['Circuit_Length_km'] * df['Laps']\n",
    "        \n",
    "        if all(col in available_cols for col in ['Track_Temperature_Celsius', 'Ambient_Temperature_Celsius']):\n",
    "            df['temp_diff'] = df['Track_Temperature_Celsius'] - df['Ambient_Temperature_Celsius']\n",
    "            \n",
    "        if all(col in available_cols for col in ['Avg_Speed_kmh', 'Track_Temperature_Celsius']):\n",
    "            df['speed_temp_interaction'] = df['Avg_Speed_kmh'] * df['Track_Temperature_Celsius']\n",
    "            \n",
    "        if all(col in available_cols for col in ['Humidity_%', 'Ambient_Temperature_Celsius']):\n",
    "            df['humidity_temp_interaction'] = df['Humidity_%'] * df['Ambient_Temperature_Celsius']\n",
    "        \n",
    "        if 'Grid_Position' in available_cols:\n",
    "            df['grid_advantage'] = 1 / (df['Grid_Position'] + 1)\n",
    "            \n",
    "        if all(col in available_cols for col in ['Championship_Points', 'Championship_Position']):\n",
    "            df['championship_momentum'] = df['Championship_Points'] / (df['Championship_Position'] + 1)\n",
    "            df['position_pressure'] = df['Championship_Position'] * df['Grid_Position'] if 'Grid_Position' in available_cols else df['Championship_Position']\n",
    "        \n",
    "        if all(col in available_cols for col in ['Tire_Compound_Front', 'Tire_Compound_Rear']):\n",
    "            df['tire_strategy'] = df['Tire_Compound_Front'].astype(str) + '_' + df['Tire_Compound_Rear'].astype(str)\n",
    "            \n",
    "        if all(col in available_cols for col in ['Tire_Degradation_Factor_per_Lap', 'Laps']):\n",
    "            df['tire_degradation_total'] = df['Tire_Degradation_Factor_per_Lap'] * df['Laps']\n",
    "        \n",
    "        if all(col in available_cols for col in ['years_active', 'Championship_Points']):\n",
    "            df['experience_points_ratio'] = df['years_active'] * df['Championship_Points']\n",
    "            \n",
    "        if all(col in available_cols for col in ['starts', 'years_active']):\n",
    "            df['starts_per_year'] = df['starts'] / (df['years_active'] + 1)\n",
    "        \n",
    "        if all(col in available_cols for col in ['Avg_Speed_kmh', 'Corners_per_Lap']):\n",
    "            df['speed_per_corner'] = df['Avg_Speed_kmh'] / (df['Corners_per_Lap'] + 1)\n",
    "            \n",
    "        if all(col in available_cols for col in ['Circuit_Length_km', 'Avg_Speed_kmh']):\n",
    "            df['theoretical_lap_time'] = (df['Circuit_Length_km'] * 3600) / (df['Avg_Speed_kmh'] + 1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    train_engineered = create_features(train_df)\n",
    "    test_engineered = create_features(test_df)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Features created! Train shape: {train_engineered.shape}\")\n",
    "    \n",
    "    return train_engineered, test_engineered\n",
    "\n",
    "train_engineered, test_engineered = phase2_feature_engineering_corrected(train, test)\n",
    "print(f\"\\nüéØ New feature count: {train_engineered.shape[1] - train.shape[1]} features added\")\n",
    "print(f\"Total features now: {train_engineered.shape[1]}\")\n",
    "\n",
    "original_cols = set(train.columns)\n",
    "new_cols = set(train_engineered.columns) - original_cols\n",
    "print(f\"\\nüÜï New features created: {len(new_cols)}\")\n",
    "for col in sorted(new_cols):\n",
    "    print(f\"   - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30566691",
   "metadata": {
    "papermill": {
     "duration": 0.003813,
     "end_time": "2025-06-14T06:17:47.981331",
     "exception": false,
     "start_time": "2025-06-14T06:17:47.977518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PHASE 3:Advanced Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632eb6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:17:47.990544Z",
     "iopub.status.busy": "2025-06-14T06:17:47.990252Z",
     "iopub.status.idle": "2025-06-14T06:18:02.797589Z",
     "shell.execute_reply": "2025-06-14T06:18:02.796676Z"
    },
    "papermill": {
     "duration": 14.813146,
     "end_time": "2025-06-14T06:18:02.798601",
     "exception": false,
     "start_time": "2025-06-14T06:17:47.985455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄ STARTING PIPELINE EXECUTION üöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄ\n",
      "\n",
      "üîß PHASE 3: ADVANCED PREPROCESSING\n",
      "==================================================\n",
      "‚úÖ Target variable separated\n",
      "‚úÖ Test IDs stored: False\n",
      "‚úÖ Categorical columns found: 14: ['category_x', 'Track_Condition', 'Tire_Compound_Front', 'Tire_Compound_Rear', 'Penalty', 'Session', 'shortname', 'circuit_name', 'rider_name', 'team_name', 'bike_name', 'weather', 'track', 'tire_strategy']\n",
      "   ‚úì Encoded category_x: 3 unique values\n",
      "   ‚úì Encoded Track_Condition: 2 unique values\n",
      "   ‚úì Encoded Tire_Compound_Front: 3 unique values\n",
      "   ‚úì Encoded Tire_Compound_Rear: 3 unique values\n",
      "   ‚úì Encoded Penalty: 6 unique values\n",
      "   ‚úì Encoded Session: 7 unique values\n",
      "   ‚úì Encoded shortname: 53 unique values\n",
      "   ‚úì Encoded circuit_name: 70 unique values\n",
      "   ‚úì Encoded rider_name: 2695 unique values\n",
      "   ‚úì Encoded team_name: 967 unique values\n",
      "   ‚úì Encoded bike_name: 301 unique values\n",
      "   ‚úì Encoded weather: 5 unique values\n",
      "   ‚úì Encoded track: 2 unique values\n",
      "   ‚úì Encoded tire_strategy: 9 unique values\n",
      "‚úÖ Preprocessing complete!\n",
      "Final train shape: (1914056, 63)\n",
      "Final test shape: (546874, 63)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"üöÄ\" * 25 + \" STARTING PIPELINE EXECUTION \" + \"üöÄ\" * 25)\n",
    "\n",
    "print(\"\\nüîß PHASE 3: ADVANCED PREPROCESSING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "train_processed = train_engineered.copy()\n",
    "test_processed = test_engineered.copy()\n",
    "\n",
    "if 'Lap_Time_Seconds' in train_processed.columns:\n",
    "    y = train_processed['Lap_Time_Seconds']\n",
    "    train_processed = train_processed.drop('Lap_Time_Seconds', axis=1)\n",
    "    print(\"‚úÖ Target variable separated\")\n",
    "\n",
    "test_ids = test_processed['Unique_ID'] if 'Unique_ID' in test_processed.columns else None\n",
    "print(f\"‚úÖ Test IDs stored: {test_ids is not None}\")\n",
    "\n",
    "id_cols = ['Unique_ID', 'id', 'ID']\n",
    "for col in id_cols:\n",
    "    if col in train_processed.columns:\n",
    "        train_processed = train_processed.drop(col, axis=1)\n",
    "    if col in test_processed.columns:\n",
    "        test_processed = test_processed.drop(col, axis=1)\n",
    "\n",
    "\n",
    "categorical_cols = train_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"‚úÖ Categorical columns found: {len(categorical_cols)}: {categorical_cols}\")\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Combine train and test for consistent encoding\n",
    "    combined_values = pd.concat([train_processed[col], test_processed[col]]).astype(str)\n",
    "    le.fit(combined_values)\n",
    "    \n",
    "    train_processed[col] = le.transform(train_processed[col].astype(str))\n",
    "    test_processed[col] = le.transform(test_processed[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    print(f\"   ‚úì Encoded {col}: {len(le.classes_)} unique values\")\n",
    "\n",
    "numeric_cols = train_processed.select_dtypes(include=[np.number]).columns\n",
    "train_processed[numeric_cols] = train_processed[numeric_cols].fillna(train_processed[numeric_cols].median())\n",
    "test_processed[numeric_cols] = test_processed[numeric_cols].fillna(train_processed[numeric_cols].median())\n",
    "\n",
    "train_processed = train_processed.replace([np.inf, -np.inf], np.nan)\n",
    "test_processed = test_processed.replace([np.inf, -np.inf], np.nan)\n",
    "train_processed = train_processed.fillna(train_processed.median())\n",
    "test_processed = test_processed.fillna(train_processed.median())\n",
    "\n",
    "print(f\"‚úÖ Preprocessing complete!\")\n",
    "print(f\"Final train shape: {train_processed.shape}\")\n",
    "print(f\"Final test shape: {test_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bafca93",
   "metadata": {
    "papermill": {
     "duration": 0.00446,
     "end_time": "2025-06-14T06:18:02.809164",
     "exception": false,
     "start_time": "2025-06-14T06:18:02.804704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Phase 4: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3cd69cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:02.819393Z",
     "iopub.status.busy": "2025-06-14T06:18:02.819115Z",
     "iopub.status.idle": "2025-06-14T06:18:03.665774Z",
     "shell.execute_reply": "2025-06-14T06:18:03.664665Z"
    },
    "papermill": {
     "duration": 0.853592,
     "end_time": "2025-06-14T06:18:03.667342",
     "exception": false,
     "start_time": "2025-06-14T06:18:02.813750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ PHASE 4: FEATURE SELECTION (Top 50)\n",
      "==================================================\n",
      "‚úÖ Selected 50 features out of 63\n",
      "\n",
      "üèÜ Top 10 Most Important Features:\n",
      "   19. team_name: 151.22\n",
      "   21. Corners_per_Lap: 138.75\n",
      "   32. with_points: 127.37\n",
      "   42. corners_per_km: 116.22\n",
      "   12. team: 104.04\n",
      "   37. years_active: 100.23\n",
      "   15. points: 96.11\n",
      "   43. distance_per_corner: 85.05\n",
      "   41. finish_rate: 84.81\n",
      "   31. finishes: 72.04\n",
      "\n",
      "‚úÖ Phase 3 & 4 completed successfully!\n",
      "üìä Ready for model training with 50 selected features\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüéØ PHASE 4: FEATURE SELECTION (Top 50)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=min(50, train_processed.shape[1]))\n",
    "X_train_selected = selector.fit_transform(train_processed, y)\n",
    "X_test_selected = selector.transform(test_processed)\n",
    "\n",
    "selected_features = train_processed.columns[selector.get_support()].tolist()\n",
    "feature_scores = selector.scores_[selector.get_support()]\n",
    "\n",
    "print(f\"‚úÖ Selected {len(selected_features)} features out of {train_processed.shape[1]}\")\n",
    "print(\"\\nüèÜ Top 10 Most Important Features:\")\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'score': feature_scores\n",
    "}).sort_values('score', ascending=False)\n",
    "\n",
    "for i, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"   {i+1:2d}. {row['feature']}: {row['score']:.2f}\")\n",
    "\n",
    "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features)\n",
    "\n",
    "print(f\"\\n‚úÖ Phase 3 & 4 completed successfully!\")\n",
    "print(f\"üìä Ready for model training with {len(selected_features)} selected features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b172a4f",
   "metadata": {
    "papermill": {
     "duration": 0.004573,
     "end_time": "2025-06-14T06:18:03.677728",
     "exception": false,
     "start_time": "2025-06-14T06:18:03.673155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Phase 5: Advanced Model Development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d66cee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:03.688390Z",
     "iopub.status.busy": "2025-06-14T06:18:03.688088Z",
     "iopub.status.idle": "2025-06-14T06:18:03.694494Z",
     "shell.execute_reply": "2025-06-14T06:18:03.693776Z"
    },
    "papermill": {
     "duration": 0.013082,
     "end_time": "2025-06-14T06:18:03.695485",
     "exception": false,
     "start_time": "2025-06-14T06:18:03.682403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ PHASE 5: ADVANCED MODEL DEVELOPMENT\n",
      "==================================================\n",
      "‚úÖ Created 5 models:\n",
      "   ‚úì Random Forest\n",
      "   ‚úì XGBoost\n",
      "   ‚úì LightGBM\n",
      "   ‚úì Ridge\n",
      "   ‚úì Lasso\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nü§ñ PHASE 5: ADVANCED MODEL DEVELOPMENT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Base models with optimized parameters\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100,  # Reduced for large dataset\n",
    "        max_depth=15,\n",
    "        min_samples_split=10,  # Increased for large dataset\n",
    "        min_samples_leaf=5,    # Increased for large dataset\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=100,   # Reduced for large dataset\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    'LightGBM': lgb.LGBMRegressor(\n",
    "        n_estimators=100,   # Reduced for large dataset\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    \n",
    "    'Ridge': Ridge(alpha=10.0),\n",
    "    \n",
    "    'Lasso': Lasso(alpha=1.0, max_iter=2000)\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Created {len(models)} models:\")\n",
    "for name in models.keys():\n",
    "    print(f\"   ‚úì {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a13e0b",
   "metadata": {
    "papermill": {
     "duration": 0.004716,
     "end_time": "2025-06-14T06:18:03.705481",
     "exception": false,
     "start_time": "2025-06-14T06:18:03.700765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Phase 6: Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "764a8105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:03.715906Z",
     "iopub.status.busy": "2025-06-14T06:18:03.715629Z",
     "iopub.status.idle": "2025-06-14T06:18:03.863645Z",
     "shell.execute_reply": "2025-06-14T06:18:03.862539Z"
    },
    "papermill": {
     "duration": 0.154712,
     "end_time": "2025-06-14T06:18:03.864777",
     "exception": false,
     "start_time": "2025-06-14T06:18:03.710065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèãÔ∏è PHASE 6: MODEL TRAINING SETUP\n",
      "==================================================\n",
      "‚úÖ Reduced training set to 100,000 samples\n",
      "üìä Training samples: 80,000\n",
      "üìä Validation samples: 20,000\n",
      "üìä Features: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüèãÔ∏è PHASE 6: MODEL TRAINING SETUP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "max_train_size = 100000\n",
    "if len(X_train_selected) > max_train_size:\n",
    "    sample_idx = np.random.choice(len(X_train_selected), max_train_size, replace=False)\n",
    "    X_train_fast = X_train_selected.iloc[sample_idx]\n",
    "    y_train_fast = y.iloc[sample_idx]\n",
    "    print(f\"‚úÖ Reduced training set to {max_train_size:,} samples\")\n",
    "else:\n",
    "    X_train_fast = X_train_selected\n",
    "    y_train_fast = y\n",
    "\n",
    "# Single train-validation split\n",
    "X_train_sub, X_val_sub, y_train_sub, y_val_sub = train_test_split(\n",
    "    X_train_fast, y_train_fast, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Training samples: {len(X_train_sub):,}\")\n",
    "print(f\"üìä Validation samples: {len(X_val_sub):,}\")\n",
    "print(f\"üìä Features: {X_train_sub.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "119c08c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:03.876592Z",
     "iopub.status.busy": "2025-06-14T06:18:03.876340Z",
     "iopub.status.idle": "2025-06-14T06:18:03.881965Z",
     "shell.execute_reply": "2025-06-14T06:18:03.881335Z"
    },
    "papermill": {
     "duration": 0.013347,
     "end_time": "2025-06-14T06:18:03.883504",
     "exception": false,
     "start_time": "2025-06-14T06:18:03.870157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ DEFINING FAST MODELS\n",
      "------------------------------\n",
      "‚úÖ Defined 4 fast models\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüöÄ DEFINING FAST MODELS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "fast_models = {\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    \n",
    "    'RandomForest_Fast': RandomForestRegressor(\n",
    "        n_estimators=50,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \n",
    "    'XGBoost_Fast': xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \n",
    "    'LightGBM_Fast': lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Defined {len(fast_models)} fast models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53d4e3f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:03.895053Z",
     "iopub.status.busy": "2025-06-14T06:18:03.894830Z",
     "iopub.status.idle": "2025-06-14T06:18:27.150208Z",
     "shell.execute_reply": "2025-06-14T06:18:27.149164Z"
    },
    "papermill": {
     "duration": 23.262523,
     "end_time": "2025-06-14T06:18:27.151688",
     "exception": false,
     "start_time": "2025-06-14T06:18:03.889165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ TRAINING MODELS\n",
      "------------------------------\n",
      "\n",
      "üîÑ Training Ridge...\n",
      "   ‚úÖ RMSE: 11.4611 | Time: 0.1s\n",
      "\n",
      "üîÑ Training RandomForest_Fast...\n",
      "   ‚úÖ RMSE: 11.2374 | Time: 20.8s\n",
      "\n",
      "üîÑ Training XGBoost_Fast...\n",
      "   ‚úÖ RMSE: 11.1059 | Time: 1.0s\n",
      "\n",
      "üîÑ Training LightGBM_Fast...\n",
      "   ‚úÖ RMSE: 11.2109 | Time: 0.8s\n",
      "\n",
      "üìä TRAINING SUMMARY\n",
      "----------------------------------------\n",
      "Ridge               : RMSE=11.4611, Time=0.1s\n",
      "RandomForest_Fast   : RMSE=11.2374, Time=20.8s\n",
      "XGBoost_Fast        : RMSE=11.1059, Time=1.0s\n",
      "LightGBM_Fast       : RMSE=11.2109, Time=0.8s\n"
     ]
    }
   ],
   "source": [
    "# MODEL TRAINING LOOP\n",
    "print(\"\\nüîÑ TRAINING MODELS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for name, model in fast_models.items():\n",
    "    print(f\"\\nüîÑ Training {name}...\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_sub, y_train_sub)\n",
    "        \n",
    "        val_pred = model.predict(X_val_sub)\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val_sub, val_pred))\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        results[name] = {\n",
    "            'Val_RMSE': val_rmse,\n",
    "            'Training_Time': training_time,\n",
    "            'model': model\n",
    "        }\n",
    "        trained_models[name] = model\n",
    "        \n",
    "        print(f\"   ‚úÖ RMSE: {val_rmse:.4f} | Time: {training_time:.1f}s\")\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nüìä TRAINING SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "for name, info in results.items():\n",
    "    print(f\"{name:<20}: RMSE={info['Val_RMSE']:.4f}, Time={info['Training_Time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6725c64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:27.163739Z",
     "iopub.status.busy": "2025-06-14T06:18:27.163477Z",
     "iopub.status.idle": "2025-06-14T06:18:28.293912Z",
     "shell.execute_reply": "2025-06-14T06:18:28.293466Z"
    },
    "papermill": {
     "duration": 1.137287,
     "end_time": "2025-06-14T06:18:28.294762",
     "exception": false,
     "start_time": "2025-06-14T06:18:27.157475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ SELECTING BEST MODEL\n",
      "------------------------------\n",
      "üèÜ BEST MODEL: XGBoost_Fast\n",
      "üéØ Best RMSE: 11.1059\n",
      "\n",
      "üìà Final training on 100,000 samples...\n",
      "‚úÖ Final training completed in 1.1s\n",
      "\n",
      "üéØ READY FOR PREDICTIONS WITH: XGBoost_Fast\n"
     ]
    }
   ],
   "source": [
    "# BEST MODEL SELECTION\n",
    "print(\"\\nüèÜ SELECTING BEST MODEL\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if results:\n",
    "    best_model_name = min(results.keys(), key=lambda x: results[x]['Val_RMSE'])\n",
    "    best_model = trained_models[best_model_name]\n",
    "    best_rmse = results[best_model_name]['Val_RMSE']\n",
    "    \n",
    "    print(f\"üèÜ BEST MODEL: {best_model_name}\")\n",
    "    print(f\"üéØ Best RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìà Final training on {len(X_train_fast):,} samples...\")\n",
    "    start_time = time.time()\n",
    "    best_model.fit(X_train_fast, y_train_fast)\n",
    "    final_training_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Final training completed in {final_training_time:.1f}s\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No models trained successfully, using Ridge fallback\")\n",
    "    best_model_name = \"Ridge\"\n",
    "    best_model = Ridge(alpha=1.0)\n",
    "    best_model.fit(X_train_fast, y_train_fast)\n",
    "\n",
    "print(f\"\\nüéØ READY FOR PREDICTIONS WITH: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16527045",
   "metadata": {
    "papermill": {
     "duration": 0.004827,
     "end_time": "2025-06-14T06:18:28.305316",
     "exception": false,
     "start_time": "2025-06-14T06:18:28.300489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PHASE 7: GENERATE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e29e791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:28.316399Z",
     "iopub.status.busy": "2025-06-14T06:18:28.316132Z",
     "iopub.status.idle": "2025-06-14T06:18:29.324801Z",
     "shell.execute_reply": "2025-06-14T06:18:29.323811Z"
    },
    "papermill": {
     "duration": 1.015898,
     "end_time": "2025-06-14T06:18:29.326209",
     "exception": false,
     "start_time": "2025-06-14T06:18:28.310311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ PHASE 7: GENERATE PREDICTIONS\n",
      "==================================================\n",
      "üîÆ Generating predictions...\n",
      "\n",
      "üìä PREDICTION STATISTICS:\n",
      "   Mean: 90.04 seconds\n",
      "   Std:  1.49 seconds\n",
      "   Min:  77.22 seconds\n",
      "   Max:  102.06 seconds\n",
      "\n",
      "‚úÖ BASIC SUBMISSION CREATED\n",
      "üìÅ File: solution.csv\n",
      "üìä Shape: (546874, 2)\n",
      "üèÜ Model: XGBoost_Fast\n",
      "\n",
      "üìã FIRST 5 PREDICTIONS:\n",
      "   Unique_ID  Lap_Time_Seconds\n",
      "0          0         90.442490\n",
      "1          1         91.103645\n",
      "2          2         89.846092\n",
      "3          3         90.351425\n",
      "4          4         91.091522\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüéØ PHASE 7: GENERATE PREDICTIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"üîÆ Generating predictions...\")\n",
    "predictions = best_model.predict(X_test_selected)\n",
    "\n",
    "print(f\"\\nüìä PREDICTION STATISTICS:\")\n",
    "print(f\"   Mean: {predictions.mean():.2f} seconds\")\n",
    "print(f\"   Std:  {predictions.std():.2f} seconds\")\n",
    "print(f\"   Min:  {predictions.min():.2f} seconds\")\n",
    "print(f\"   Max:  {predictions.max():.2f} seconds\")\n",
    "\n",
    "# Handle test IDs\n",
    "if 'test_ids' in locals() and test_ids is not None:\n",
    "    submission_ids = test_ids\n",
    "else:\n",
    "    submission_ids = range(len(predictions))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Unique_ID': submission_ids,\n",
    "    'Lap_Time_Seconds': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('solution.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ BASIC SUBMISSION CREATED\")\n",
    "print(f\"üìÅ File: solution.csv\")\n",
    "print(f\"üìä Shape: {submission.shape}\")\n",
    "print(f\"üèÜ Model: {best_model_name}\")\n",
    "\n",
    "print(f\"\\nüìã FIRST 5 PREDICTIONS:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85014d60",
   "metadata": {
    "papermill": {
     "duration": 0.005185,
     "end_time": "2025-06-14T06:18:29.337361",
     "exception": false,
     "start_time": "2025-06-14T06:18:29.332176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PHASE 8: FAST ENSEMBLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0006b5a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:29.349065Z",
     "iopub.status.busy": "2025-06-14T06:18:29.348808Z",
     "iopub.status.idle": "2025-06-14T06:18:31.378701Z",
     "shell.execute_reply": "2025-06-14T06:18:31.377545Z"
    },
    "papermill": {
     "duration": 2.037257,
     "end_time": "2025-06-14T06:18:31.379819",
     "exception": false,
     "start_time": "2025-06-14T06:18:29.342562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ PHASE 8: FAST ENSEMBLE\n",
      "========================================\n",
      "üîÑ Generating ensemble predictions...\n",
      "   ‚úÖ Ridge: weight=0.087\n",
      "   ‚úÖ RandomForest_Fast: weight=0.089\n",
      "   ‚úÖ LightGBM_Fast: weight=0.089\n",
      "\n",
      "‚úÖ ENSEMBLE CREATED\n",
      "üìä Models combined: 4\n",
      "üèÜ Best model weight: 0.5\n",
      "\n",
      "üìä ENSEMBLE STATISTICS:\n",
      "   Mean: 90.05 seconds\n",
      "   Std:  0.98 seconds\n",
      "   Min:  81.24 seconds\n",
      "   Max:  98.52 seconds\n",
      "\n",
      "‚úÖ ENSEMBLE SUBMISSION CREATED\n",
      "üìÅ File: solution_ensemble.csv\n",
      "\n",
      "üèÅ PIPELINE COMPLETED\n",
      "üìÅ Files created: solution.csv, solution_ensemble.csv\n",
      "üöÄ Ready for Kaggle submission!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüöÄ PHASE 8: FAST ENSEMBLE\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "ensemble_preds = []\n",
    "ensemble_weights = []\n",
    "\n",
    "print(\"üîÑ Generating ensemble predictions...\")\n",
    "\n",
    "for name, model_info in results.items():\n",
    "    if name != best_model_name:\n",
    "        try:\n",
    "            pred = trained_models[name].predict(X_test_selected)\n",
    "            ensemble_preds.append(pred)\n",
    "            weight = 1.0 / model_info['Val_RMSE']\n",
    "            ensemble_weights.append(weight)\n",
    "            print(f\"   ‚úÖ {name}: weight={weight:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå {name}: {e}\")\n",
    "            continue\n",
    "\n",
    "if len(ensemble_preds) >= 2:\n",
    "    ensemble_weights = np.array(ensemble_weights)\n",
    "    ensemble_weights = ensemble_weights / ensemble_weights.sum()\n",
    "    \n",
    "    blended_pred = np.zeros(len(predictions))\n",
    "    for i, pred in enumerate(ensemble_preds):\n",
    "        blended_pred += ensemble_weights[i] * pred\n",
    "    \n",
    "    best_weight = 0.5\n",
    "    final_pred = best_weight * predictions + (1 - best_weight) * blended_pred\n",
    "    \n",
    "    print(f\"\\n‚úÖ ENSEMBLE CREATED\")\n",
    "    print(f\"üìä Models combined: {len(ensemble_preds)+1}\")\n",
    "    print(f\"üèÜ Best model weight: {best_weight}\")\n",
    "    \n",
    "    ensemble_submission = pd.DataFrame({\n",
    "        'Unique_ID': submission_ids,\n",
    "        'Lap_Time_Seconds': final_pred\n",
    "    })\n",
    "    \n",
    "    ensemble_submission.to_csv('solution_ensemble.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nüìä ENSEMBLE STATISTICS:\")\n",
    "    print(f\"   Mean: {final_pred.mean():.2f} seconds\")\n",
    "    print(f\"   Std:  {final_pred.std():.2f} seconds\")\n",
    "    print(f\"   Min:  {final_pred.min():.2f} seconds\")\n",
    "    print(f\"   Max:  {final_pred.max():.2f} seconds\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ ENSEMBLE SUBMISSION CREATED\")\n",
    "    print(f\"üìÅ File: solution_ensemble.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough models for ensemble, using single model\")\n",
    "\n",
    "print(f\"\\nüèÅ PIPELINE COMPLETED\")\n",
    "print(f\"üìÅ Files created: solution.csv\" + (\", solution_ensemble.csv\" if len(ensemble_preds) >= 2 else \"\"))\n",
    "print(\"üöÄ Ready for Kaggle submission!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef37720",
   "metadata": {
    "papermill": {
     "duration": 0.005053,
     "end_time": "2025-06-14T06:18:31.390651",
     "exception": false,
     "start_time": "2025-06-14T06:18:31.385598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ADVANCED METHODS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f994ebf3",
   "metadata": {
    "papermill": {
     "duration": 0.004974,
     "end_time": "2025-06-14T06:18:31.400919",
     "exception": false,
     "start_time": "2025-06-14T06:18:31.395945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PHASE 9: ADVANCED FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b07c2a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:31.413812Z",
     "iopub.status.busy": "2025-06-14T06:18:31.413557Z",
     "iopub.status.idle": "2025-06-14T06:18:33.904415Z",
     "shell.execute_reply": "2025-06-14T06:18:33.903426Z"
    },
    "papermill": {
     "duration": 2.499433,
     "end_time": "2025-06-14T06:18:33.905527",
     "exception": false,
     "start_time": "2025-06-14T06:18:31.406094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† PHASE 9: ADVANCED FEATURE ENGINEERING\n",
      "==================================================\n",
      "üöÄ Applying advanced feature engineering...\n",
      "üîß Creating polynomial features...\n",
      "‚úÖ Added 55 polynomial features\n",
      "üéØ Creating target encoding features...\n",
      "‚úÖ Added target encoding for 0 categorical features\n",
      "üìä Creating statistical features...\n",
      "‚úÖ Added 5 statistical features\n",
      "üèÅ Creating domain-specific racing features...\n",
      "‚úÖ Added domain-specific features\n",
      "üéØ Selecting best features...\n",
      "‚úÖ Selected 111 best features\n",
      "üìä Final feature count: 111\n",
      "\n",
      "üéØ ADVANCED FEATURES READY\n",
      "üìä Training shape: (100000, 111)\n",
      "üìä Test shape: (546874, 111)\n",
      "üöÄ Feature count increased from 50 to 111\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüß† PHASE 9: ADVANCED FEATURE ENGINEERING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def create_winning_features(X_train, X_test, y_train):\n",
    "        \n",
    "    X_train_adv = X_train.copy()\n",
    "    X_test_adv = X_test.copy()\n",
    "    \n",
    "    print(\"üîß Creating polynomial features...\")\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    numeric_cols = X_train.select_dtypes(include=[np.number]).columns[:10]\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    \n",
    "    X_train_poly = poly.fit_transform(X_train[numeric_cols])\n",
    "    X_test_poly = poly.transform(X_test[numeric_cols])\n",
    "    \n",
    "    poly_feature_names = [f\"poly_{i}\" for i in range(X_train_poly.shape[1])]\n",
    "    \n",
    "    for i, name in enumerate(poly_feature_names):\n",
    "        X_train_adv[name] = X_train_poly[:, i]\n",
    "        X_test_adv[name] = X_test_poly[:, i]\n",
    "    \n",
    "    print(f\"‚úÖ Added {len(poly_feature_names)} polynomial features\")\n",
    "    \n",
    "    print(\"üéØ Creating target encoding features...\")\n",
    "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    for col in categorical_cols[:5]:  # Limit to top 5 categorical\n",
    "        if col in X_train.columns:\n",
    "            target_mean = X_train.groupby(col)[y_train.name if hasattr(y_train, 'name') else 'target'].transform('mean')\n",
    "            X_train_adv[f'{col}_target_enc'] = target_mean\n",
    "            \n",
    "            # For test, use global mean for unseen categories\n",
    "            col_means = pd.Series(y_train).groupby(X_train[col]).mean()\n",
    "            X_test_adv[f'{col}_target_enc'] = X_test[col].map(col_means).fillna(y_train.mean())\n",
    "    \n",
    "    print(f\"‚úÖ Added target encoding for {min(len(categorical_cols), 5)} categorical features\")\n",
    "    \n",
    "    print(\"üìä Creating statistical features...\")\n",
    "    numeric_features = X_train_adv.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    if len(numeric_features) > 5:\n",
    "        feature_subset = numeric_features[:15]  # Top 15 numeric features\n",
    "        \n",
    "        # Row-wise statistics\n",
    "        X_train_adv['row_mean'] = X_train_adv[feature_subset].mean(axis=1)\n",
    "        X_train_adv['row_std'] = X_train_adv[feature_subset].std(axis=1)\n",
    "        X_train_adv['row_max'] = X_train_adv[feature_subset].max(axis=1)\n",
    "        X_train_adv['row_min'] = X_train_adv[feature_subset].min(axis=1)\n",
    "        X_train_adv['row_range'] = X_train_adv['row_max'] - X_train_adv['row_min']\n",
    "        \n",
    "        X_test_adv['row_mean'] = X_test_adv[feature_subset].mean(axis=1)\n",
    "        X_test_adv['row_std'] = X_test_adv[feature_subset].std(axis=1)\n",
    "        X_test_adv['row_max'] = X_test_adv[feature_subset].max(axis=1)\n",
    "        X_test_adv['row_min'] = X_test_adv[feature_subset].min(axis=1)\n",
    "        X_test_adv['row_range'] = X_test_adv['row_max'] - X_test_adv['row_min']\n",
    "        \n",
    "        print(\"‚úÖ Added 5 statistical features\")\n",
    "    \n",
    "    print(\"üèÅ Creating domain-specific racing features...\")\n",
    "    if 'Grid_Position' in X_train_adv.columns and 'Championship_Position' in X_train_adv.columns:\n",
    "        X_train_adv['pressure_index'] = X_train_adv['Grid_Position'] * X_train_adv['Championship_Position']\n",
    "        X_test_adv['pressure_index'] = X_test_adv['Grid_Position'] * X_test_adv['Championship_Position']\n",
    "    \n",
    "    if 'Avg_Speed_kmh' in X_train_adv.columns and 'Circuit_Length_km' in X_train_adv.columns:\n",
    "        X_train_adv['speed_per_km'] = X_train_adv['Avg_Speed_kmh'] / (X_train_adv['Circuit_Length_km'] + 0.1)\n",
    "        X_test_adv['speed_per_km'] = X_test_adv['Avg_Speed_kmh'] / (X_test_adv['Circuit_Length_km'] + 0.1)\n",
    "    \n",
    "    if 'Track_Temperature_Celsius' in X_train_adv.columns and 'Humidity_%' in X_train_adv.columns:\n",
    "        X_train_adv['weather_factor'] = X_train_adv['Track_Temperature_Celsius'] * X_train_adv['Humidity_%'] / 100\n",
    "        X_test_adv['weather_factor'] = X_test_adv['Track_Temperature_Celsius'] * X_test_adv['Humidity_%'] / 100\n",
    "    \n",
    "    print(\"‚úÖ Added domain-specific features\")\n",
    "    \n",
    "    print(\"üéØ Selecting best features...\")\n",
    "    from sklearn.feature_selection import SelectKBest, f_regression\n",
    "    \n",
    "    X_train_adv = X_train_adv.replace([np.inf, -np.inf], np.nan)\n",
    "    X_test_adv = X_test_adv.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    X_train_adv = X_train_adv.fillna(X_train_adv.median())\n",
    "    X_test_adv = X_test_adv.fillna(X_train_adv.median())\n",
    "    \n",
    "    max_features = min(500, X_train_adv.shape[1])  # Max 500 features\n",
    "    selector = SelectKBest(score_func=f_regression, k=max_features)\n",
    "    \n",
    "    X_train_selected = selector.fit_transform(X_train_adv, y_train)\n",
    "    X_test_selected = selector.transform(X_test_adv)\n",
    "    \n",
    "    selected_feature_names = X_train_adv.columns[selector.get_support()].tolist()\n",
    "    \n",
    "    print(f\"‚úÖ Selected {len(selected_feature_names)} best features\")\n",
    "    print(f\"üìä Final feature count: {X_train_selected.shape[1]}\")\n",
    "    \n",
    "    return X_train_selected, X_test_selected, selected_feature_names\n",
    "\n",
    "print(\"üöÄ Applying advanced feature engineering...\")\n",
    "X_train_advanced, X_test_advanced, advanced_features = create_winning_features(\n",
    "    pd.DataFrame(X_train_fast, columns=selected_features), \n",
    "    pd.DataFrame(X_test_selected, columns=selected_features),\n",
    "    y_train_fast\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ ADVANCED FEATURES READY\")\n",
    "print(f\"üìä Training shape: {X_train_advanced.shape}\")\n",
    "print(f\"üìä Test shape: {X_test_advanced.shape}\")\n",
    "print(f\"üöÄ Feature count increased from {len(selected_features)} to {len(advanced_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ccf6ca",
   "metadata": {
    "papermill": {
     "duration": 0.005266,
     "end_time": "2025-06-14T06:18:33.916818",
     "exception": false,
     "start_time": "2025-06-14T06:18:33.911552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PHASE 10: COMPETITION-WINNING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1c5a577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T06:18:33.929013Z",
     "iopub.status.busy": "2025-06-14T06:18:33.928771Z",
     "iopub.status.idle": "2025-06-14T06:30:18.824919Z",
     "shell.execute_reply": "2025-06-14T06:30:18.823756Z"
    },
    "papermill": {
     "duration": 704.904689,
     "end_time": "2025-06-14T06:30:18.826903",
     "exception": false,
     "start_time": "2025-06-14T06:18:33.922214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ PHASE 10: COMPETITION-WINNING MODELS\n",
      "==================================================\n",
      "üöÄ Defined 5 competition-grade models\n",
      "\n",
      "üîÑ TRAINING ADVANCED MODELS\n",
      "----------------------------------------\n",
      "\n",
      "üîÑ Training XGBoost_Tuned...\n",
      "   ‚úÖ RMSE: 10.8094 | Time: 16.6s\n",
      "\n",
      "üîÑ Training LightGBM_Tuned...\n",
      "   ‚úÖ RMSE: 11.1779 | Time: 3.1s\n",
      "\n",
      "üîÑ Training ExtraTrees_Tuned...\n",
      "   ‚úÖ RMSE: 11.3727 | Time: 9.6s\n",
      "\n",
      "üîÑ Training GradientBoosting_Tuned...\n",
      "   ‚úÖ RMSE: 11.2624 | Time: 631.5s\n",
      "\n",
      "üîÑ Training RandomForest_Tuned...\n",
      "   ‚úÖ RMSE: 11.3508 | Time: 31.7s\n",
      "\n",
      "üèÜ ADVANCED MODEL RESULTS\n",
      "--------------------------------------------------\n",
      "XGBoost_Tuned            : RMSE=10.8094, Time=16.6s\n",
      "LightGBM_Tuned           : RMSE=11.1779, Time=3.1s\n",
      "GradientBoosting_Tuned   : RMSE=11.2624, Time=631.5s\n",
      "RandomForest_Tuned       : RMSE=11.3508, Time=31.7s\n",
      "ExtraTrees_Tuned         : RMSE=11.3727, Time=9.6s\n",
      "\n",
      "üèÜ BEST ADVANCED MODEL: XGBoost_Tuned\n",
      "üéØ Best RMSE: 10.8094\n",
      "üìà Final training on advanced features...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüèÜ PHASE 10: COMPETITION-WINNING MODELS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Advanced hyperparameter-tuned models\n",
    "winning_models = {\n",
    "    'XGBoost_Tuned': xgb.XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    'LightGBM_Tuned': lgb.LGBMRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        min_child_samples=20,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    \n",
    "    'ExtraTrees_Tuned': ExtraTreesRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=3,\n",
    "        max_features='sqrt',\n",
    "        bootstrap=False,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    'GradientBoosting_Tuned': GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \n",
    "    'RandomForest_Tuned': RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=3,\n",
    "        max_features='sqrt',\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"üöÄ Defined {len(winning_models)} competition-grade models\")\n",
    "\n",
    "# Train advanced models\n",
    "advanced_results = {}\n",
    "advanced_trained_models = {}\n",
    "\n",
    "# Create train-validation split for advanced features\n",
    "X_train_adv_sub, X_val_adv_sub, y_train_adv_sub, y_val_adv_sub = train_test_split(\n",
    "    X_train_advanced, y_train_fast, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nüîÑ TRAINING ADVANCED MODELS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for name, model in winning_models.items():\n",
    "    print(f\"\\nüîÑ Training {name}...\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_adv_sub, y_train_adv_sub)\n",
    "        \n",
    "        val_pred = model.predict(X_val_adv_sub)\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val_adv_sub, val_pred))\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        advanced_results[name] = {\n",
    "            'Val_RMSE': val_rmse,\n",
    "            'Training_Time': training_time,\n",
    "            'model': model\n",
    "        }\n",
    "        advanced_trained_models[name] = model\n",
    "        \n",
    "        print(f\"   ‚úÖ RMSE: {val_rmse:.4f} | Time: {training_time:.1f}s\")\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nüèÜ ADVANCED MODEL RESULTS\")\n",
    "print(\"-\" * 50)\n",
    "sorted_models = sorted(advanced_results.items(), key=lambda x: x[1]['Val_RMSE'])\n",
    "for name, info in sorted_models:\n",
    "    print(f\"{name:<25}: RMSE={info['Val_RMSE']:.4f}, Time={info['Training_Time']:.1f}s\")\n",
    "\n",
    "# Select best advanced model\n",
    "if advanced_results:\n",
    "    best_advanced_name = min(advanced_results.keys(), key=lambda x: advanced_results[x]['Val_RMSE'])\n",
    "    best_advanced_model = advanced_trained_models[best_advanced_name]\n",
    "    best_advanced_rmse = advanced_results[best_advanced_name]['Val_RMSE']\n",
    "    \n",
    "    print(f\"\\nüèÜ BEST ADVANCED MODEL: {best_advanced_name}\")\n",
    "    print(f\"üéØ Best RMSE: {best_advanced_rmse:.4f}\")\n",
    "    \n",
    "    # Final training on all advanced data\n",
    "    print(f\"üìà Final training on advanced features...\")\n",
    "    best_advanced_model.fit(X_train_advanced, y_train_fast)\n",
    "    \n",
    "else:\n",
    "    best_advanced_name = \"XGBoost_Tuned\"\n",
    "    best_advanced_model = winning_models[best_advanced_name]\n",
    "    best_advanced_model.fit(X_train_advanced, y_train_fast)\n",
    "    print(\"‚úÖ Using XGBoost fallback\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12651513,
     "sourceId": 104857,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 788.813461,
   "end_time": "2025-06-14T06:30:20.259792",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-14T06:17:11.446331",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
